{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings for Mahabharat Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import pprint\n",
    "sys.path.append('')\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp = pp.pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "import tiktoken\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.vectorstores.pgvector import PGVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv('./.env') \n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n",
    "os.environ[\"LANGCHAIN_SESSION\"] = \"Ankush Project\"\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "text_embedding_model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/Users/rahulnayak/TechWork/Python projects/mahabharata/books\"\n",
    "loader = DirectoryLoader(\"/Users/rahulnayak/TechWork/Python projects/mahabharata/books\", glob=\"*.txt\",  show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:23<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size=500\n",
    "chunk_overlap=30\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size, \n",
    "    chunk_overlap = chunk_overlap,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39306"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the cost of embedding the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)\n",
    "\n",
    "# Initialize the TiktokenTokenizer\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def num_tokens_from_string(string, encoding_name=\"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "tokens_l = []\n",
    "for doc in docs:\n",
    "    tokens_l = tokens_l + [num_tokens_from_string(doc.page_content)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document, number of tokens =  [45757, 321881, 125423, 106103, 11409, 4449, 450887, 365834, 414485, 724577, 237599, 29304, 87564, 266427, 30178, 196033, 131876, 12398]\n",
      "Total Tokens =  3562184\n",
      "Total embedding cost:  0.35621840000000005\n"
     ]
    }
   ],
   "source": [
    "ada_cost_per_k_token = 0.0001\n",
    "total_ada_cost =  sum(tokens_l)*ada_cost_per_k_token/1000\n",
    "\n",
    "print(\"Document, number of tokens = \", tokens_l)\n",
    "print(\"Total Tokens = \", sum(tokens_l))\n",
    "print(\"Total embedding cost: \", total_ada_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to PG Vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=\"psycopg2\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=os.environ[\"PGVECTOR_DATABASE\"],\n",
    "    user=os.environ[\"PGVECTOR_USER\"],\n",
    "    password=os.environ[\"PGVECTOR_PASSWORD\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Embeddings and persist to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(model=text_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_previous_data=True\n",
    "# COLLECTION_NAME = \"mh_embeddings_500\"\n",
    "COLLECTION_NAME = \"mh_embeddings_500\"\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embedding,\n",
    "    documents=splits,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=delete_previous_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
