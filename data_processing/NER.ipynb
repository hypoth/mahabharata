{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnayak/.pyenv/versions/3.11.1/envs/OpenAI@3111/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import statistics\n",
    "# import json\n",
    "# import tiktoken\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "##\n",
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model \n",
    "\n",
    "Roberta Named Entity works best for this task. \n",
    "\n",
    "Using this version from HF : `mn-xlm-roberta-base-named-entity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters -> 277.456901 Mn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "## Roberta based NER\n",
    "roberta = pipeline(\"token-classification\", model=\"2rtl3/mn-xlm-roberta-base-named-entity\", aggregation_strategy=\"simple\")\n",
    "\n",
    "print(\"Number of parameters ->\", roberta.model.num_parameters()/1000000, \"Mn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LOC', 'MISC', 'O', 'ORG', 'PER']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "entity_classes = list(roberta.model.config.label2id.keys())\n",
    "entity_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Named entites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the model for multiple text\n",
    "\n",
    "first lets run a test on example text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"The Rishi Vyasa published this mass of knowledge in both a detailed and\n",
    "an abridged form. It is the wish of the learned in the world to possess\n",
    "the details and the abridgement. Some read the Bharata beginning with the\n",
    "initial mantra (invocation), others with the story of Astika, others with\n",
    "Uparichara, while some Brahmanas study the whole. Men of learning display\n",
    "their various knowledge of the institutes in commenting on the\n",
    "composition. Some are skilful in explaining it, while others, in\n",
    "remembering its contents.\n",
    "\n",
    "The son of Satyavati having, by penance and meditation, analysed the\n",
    "eternal Veda, afterwards composed this holy history, when that learned\n",
    "Brahmarshi of strict vows, the noble Dwaipayana Vyasa, offspring of\n",
    "Parasara, had finished this greatest of narrations, he began to consider\n",
    "how he might teach it to his disciples. And the possessor of the six\n",
    "attributes, Brahma, the world's preceptor, knowing of the anxiety of the\n",
    "Rishi Dwaipayana, came in person to the place where the latter was, for\n",
    "gratifying the saint, and benefiting the people. And when Vyasa,\n",
    "surrounded by all the tribes of Munis, saw him, he was surprised; and,\n",
    "standing with joined palms, he bowed and ordered a seat to be brought.\n",
    "And Vyasa having gone round him who is called Hiranyagarbha seated on\n",
    "that distinguished seat stood near it; and being commanded by Brahma\n",
    "Parameshthi, he sat down near the seat, full of affection and smiling in\n",
    "joy. Then the greatly glorious Vyasa, addressing Brahma Parameshthi,\n",
    "said, \"O divine Brahma, by me a poem hath been composed which is greatly\n",
    "respected. The mystery of the Veda, and what other subjects have been\n",
    "explained by me; the various rituals of the Upanishads with the Angas;\n",
    "the compilation of the Puranas and history formed by me and named after\n",
    "the three divisions of time, past, present, and future; the determination\n",
    "of the nature of decay, fear, disease, existence, and non-existence, a\n",
    "description of creeds and of the various modes of life; rule for the four\n",
    "castes, and the import of all the Puranas; an account of asceticism and\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the combine_tokens_list function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'The Rishi Vyasa', 'entity': 'MISC'},\n",
       " {'name': 'the Bharata', 'entity': 'MISC'},\n",
       " {'name': 'Astika', 'entity': 'PER'},\n",
       " {'name': 'Uparichara', 'entity': 'PER'},\n",
       " {'name': 'Brahmanas', 'entity': 'MISC'},\n",
       " {'name': 'Satyavati', 'entity': 'PER'},\n",
       " {'name': 'Veda', 'entity': 'MISC'},\n",
       " {'name': 'Brahmarshi', 'entity': 'PER'},\n",
       " {'name': 'Dwaipayana Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Parasara', 'entity': 'PER'},\n",
       " {'name': 'Brahma', 'entity': 'PER'},\n",
       " {'name': 'the Rishi Dwaipayana', 'entity': 'MISC'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Munis', 'entity': 'LOC'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Hiranyagarbha', 'entity': 'PER'},\n",
       " {'name': 'Brahma Parameshthi', 'entity': 'PER'},\n",
       " {'name': 'Vyasa', 'entity': 'PER'},\n",
       " {'name': 'Brahma Parameshthi', 'entity': 'PER'},\n",
       " {'name': 'Brahma', 'entity': 'PER'},\n",
       " {'name': 'the Veda', 'entity': 'MISC'},\n",
       " {'name': 'the Upanishads', 'entity': 'MISC'},\n",
       " {'name': 'the Angas', 'entity': 'MISC'},\n",
       " {'name': 'the Puranas', 'entity': 'MISC'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results = roberta(text)\n",
    "# entities = combine_tokens_list(ner_results, stop_words, metadata = {'some': 'other'})\n",
    "entities = []\n",
    "for result in ner_results:\n",
    "    entities = entities + [{'name': result['word'], 'entity': result['entity_group']}]\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a reverse indexed entities dataframe here \n",
    "\n",
    "The idea is to create a dataframe of entities and tag every section they appear in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reverse index\n",
    "## Index all the text chunks that contain a particular named entity. \n",
    "\n",
    "def row2NamedEntities(row):\n",
    "    # print(row)\n",
    "    ner_results = roberta(row['text'])\n",
    "    metadata = {'chunk_id': row['chunk_id']}\n",
    "    entities = []\n",
    "    for result in ner_results:\n",
    "        entities = entities + [{'name': result['word'], 'entity': result['entity_group'], **metadata}]\n",
    "        \n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfText2DfNE(dataframe):\n",
    "    ## Takes a dataframe from the parsed data and returns dataframe with named entities. \n",
    "    ## The input dataframe must have a text and a chunk_id column. \n",
    "\n",
    "    ## Using swifter for parallelism\n",
    "    ## 1. Calculate named entities for each row of the dataframe. \n",
    "    results = dataframe.swifter.apply(row2NamedEntities, axis=1)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities. \n",
    "    entities_list = np.concatenate(results).ravel().tolist()\n",
    "\n",
    "    ## Remove all NaN entities\n",
    "    entities_dataframe = pd.DataFrame(entities_list).replace(' ', np.nan)\n",
    "    entities_dataframe = entities_dataframe.dropna(subset=['entity'])\n",
    "\n",
    "    ## Count the number of occurances per chunk id\n",
    "    entities_dataframe = entities_dataframe.groupby(['name', 'entity', 'chunk_id']).size().reset_index(name='count')\n",
    "\n",
    "    return entities_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 200/200 [00:19<00:00, 10.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>1a00148597ad4c9fb0d28d7c995464a5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>5599d1215dcb4d6997b0e9fb21547d19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>5f7d365beb5e47fe902f2ab4be94b280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>7bf09d34692045ac97caec5928a4b0cb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhimanyu</td>\n",
       "      <td>PER</td>\n",
       "      <td>829c333210ed434ab7e6271a2c78d23d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>vati</td>\n",
       "      <td>PER</td>\n",
       "      <td>2a373dfbce2d407896ab04d516e908de</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>vigaha</td>\n",
       "      <td>PER</td>\n",
       "      <td>674b31b7880647269b35261e48681ed2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>yagandha</td>\n",
       "      <td>PER</td>\n",
       "      <td>0926195140d545eb88d41a372bae32d2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>yana</td>\n",
       "      <td>LOC</td>\n",
       "      <td>2cdda076d2204add9c42ef6d92b07bfe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>yodhana</td>\n",
       "      <td>PER</td>\n",
       "      <td>99d3342523924276ba838b17a8a4dd49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1328 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name entity                          chunk_id  count\n",
       "0     Abhimanyu    PER  1a00148597ad4c9fb0d28d7c995464a5      1\n",
       "1     Abhimanyu    PER  5599d1215dcb4d6997b0e9fb21547d19      3\n",
       "2     Abhimanyu    PER  5f7d365beb5e47fe902f2ab4be94b280      1\n",
       "3     Abhimanyu    PER  7bf09d34692045ac97caec5928a4b0cb      1\n",
       "4     Abhimanyu    PER  829c333210ed434ab7e6271a2c78d23d      1\n",
       "...         ...    ...                               ...    ...\n",
       "1323       vati    PER  2a373dfbce2d407896ab04d516e908de      1\n",
       "1324     vigaha    PER  674b31b7880647269b35261e48681ed2      1\n",
       "1325   yagandha    PER  0926195140d545eb88d41a372bae32d2      1\n",
       "1326       yana    LOC  2cdda076d2204add9c42ef6d92b07bfe      1\n",
       "1327    yodhana    PER  99d3342523924276ba838b17a8a4dd49      1\n",
       "\n",
       "[1328 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_directory = directory/\"named_entities\"\n",
    "file_list = glob.glob(f\"{directory}/*.csv\")\n",
    "df_text = pd.read_csv(directory/\"tiny_tales_summaries.csv\", sep=\"|\")\n",
    "dfne = dfText2DfNE(df_text)\n",
    "dfne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse Index each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename : summaries_combined.csv ...\n",
      "Skipping:  summaries_combined.csv\n",
      "Filename : tiny_tales_summaries.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 200/200 [00:19<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : tiny_tales_summaries_named_entities.csv\n",
      "Filename : km_ganguli_translation_6.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 627/627 [02:09<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_6_named_entities.csv\n",
      "Filename : km_ganguli_translation_14.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 358/358 [01:09<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_14_named_entities.csv\n",
      "Filename : km_ganguli_translation_15.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 136/136 [00:25<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_15_named_entities.csv\n",
      "Filename : km_ganguli_translation_7.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 955/955 [03:20<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_7_named_entities.csv\n",
      "Filename : km_ganguli_translation_5.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 756/756 [02:30<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_5_named_entities.csv\n",
      "Filename : km_ganguli_translation_17.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_17_named_entities.csv\n",
      "Filename : km_ganguli_translation_16.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 32/32 [00:06<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_16_named_entities.csv\n",
      "Filename : km_ganguli_translation_4.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 261/261 [00:50<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_4_named_entities.csv\n",
      "Filename : km_ganguli_translation_12.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1970/1970 [07:13<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_12_named_entities.csv\n",
      "Filename : km_ganguli_translation_13.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1054/1054 [03:56<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_13_named_entities.csv\n",
      "Filename : km_ganguli_translation_1.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 951/951 [03:26<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_1_named_entities.csv\n",
      "Filename : km_ganguli_translation_3.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1260/1260 [04:58<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_3_named_entities.csv\n",
      "Filename : tiny_tales_glossary.csv ...\n",
      "Skipping:  tiny_tales_glossary.csv\n",
      "Filename : km_ganguli_translation_11.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 89/89 [00:20<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_11_named_entities.csv\n",
      "Filename : km_ganguli_translation_10.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 87/87 [00:18<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_10_named_entities.csv\n",
      "Filename : km_ganguli_translation_2.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 309/309 [01:04<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_2_named_entities.csv\n",
      "Filename : km_ganguli_translation_9.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 334/334 [01:17<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_9_named_entities.csv\n",
      "Filename : kaggle_tilak_summaries.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 2376/2376 [04:04<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : kaggle_tilak_summaries_named_entities.csv\n",
      "Filename : km_ganguli_translation_8.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 498/498 [01:40<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_8_named_entities.csv\n",
      "Filename : km_ganguli_translation_18.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 38/38 [00:07<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : km_ganguli_translation_18_named_entities.csv\n",
      "Filename : wikipedia_parva_summaries.csv ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 19/19 [00:02<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file : wikipedia_parva_summaries_named_entities.csv\n"
     ]
    }
   ],
   "source": [
    "ner_directory = directory/\"named_entities\"\n",
    "file_list = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "for file in file_list:\n",
    "    file_name = file.split(\"/\")[-1]\n",
    "    print(\"Filename :\", file_name, '...')\n",
    "    if file_name in ['tiny_tales_glossary.csv', 'summaries_combined.csv']:\n",
    "    # if not file_name in ['wikipedia_parva_summaries.csv']:\n",
    "        print('Skipping: ', file_name)\n",
    "        continue\n",
    "\n",
    "    df_text = pd.read_csv(directory/file_name, sep=\"|\")\n",
    "    df_ne = dfText2DfNE(df_text)\n",
    "    df_ne['file'] = file_name\n",
    "    outfile_name = f\"{file_name.replace('.csv', '_named_entities.csv')}\"\n",
    "    df_ne.to_csv(ner_directory/outfile_name, index=False, sep=\"|\")\n",
    "    print(\"Wrote file :\", outfile_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
