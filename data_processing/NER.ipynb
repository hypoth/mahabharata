{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import statistics\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"../data\")\n",
    "from langchain.document_loaders import DataFrameLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_number</th>\n",
       "      <th>section</th>\n",
       "      <th>section_name</th>\n",
       "      <th>text</th>\n",
       "      <th>para_number</th>\n",
       "      <th>book_name</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1</td>\n",
       "      <td>SECTION CCXXXV</td>\n",
       "      <td>Khandava-daha Parva continued</td>\n",
       "      <td>\\n\\n\"Vaisampayana said, 'O thou of Kuru's race...</td>\n",
       "      <td>1</td>\n",
       "      <td>Adi Parva</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1</td>\n",
       "      <td>SECTION CCXXXV</td>\n",
       "      <td>Khandava-daha Parva continued</td>\n",
       "      <td>\"Hearing these words, Mandapala replied, 'I do...</td>\n",
       "      <td>2</td>\n",
       "      <td>Adi Parva</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>SECTION CCXXXV</td>\n",
       "      <td>Khandava-daha Parva continued</td>\n",
       "      <td>\"Vaisampayana continued, 'After this, all his ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Adi Parva</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>SECTION CCXXXVI</td>\n",
       "      <td>Khandava-daha Parva continued</td>\n",
       "      <td>\\n\\n\"Vaisampayana said, 'Mandapala then addres...</td>\n",
       "      <td>1</td>\n",
       "      <td>Adi Parva</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1</td>\n",
       "      <td>SECTION CCXXXVI</td>\n",
       "      <td>Khandava-daha Parva continued</td>\n",
       "      <td>END OF ADI PARVA\\n\\nFOOTNOTES\\n\\n1. These are ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Adi Parva</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     book_number          section                   section_name  \\\n",
       "737            1   SECTION CCXXXV  Khandava-daha Parva continued   \n",
       "738            1   SECTION CCXXXV  Khandava-daha Parva continued   \n",
       "739            1   SECTION CCXXXV  Khandava-daha Parva continued   \n",
       "740            1  SECTION CCXXXVI  Khandava-daha Parva continued   \n",
       "741            1  SECTION CCXXXVI  Khandava-daha Parva continued   \n",
       "\n",
       "                                                  text  para_number  \\\n",
       "737  \\n\\n\"Vaisampayana said, 'O thou of Kuru's race...            1   \n",
       "738  \"Hearing these words, Mandapala replied, 'I do...            2   \n",
       "739  \"Vaisampayana continued, 'After this, all his ...            3   \n",
       "740  \\n\\n\"Vaisampayana said, 'Mandapala then addres...            1   \n",
       "741  END OF ADI PARVA\\n\\nFOOTNOTES\\n\\n1. These are ...            2   \n",
       "\n",
       "     book_name  num_tokens  \n",
       "737  Adi Parva         511  \n",
       "738  Adi Parva         726  \n",
       "739  Adi Parva          41  \n",
       "740  Adi Parva         665  \n",
       "741  Adi Parva          12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'km_ganguli_translation_1.csv'\n",
    "df = pd.read_csv(directory/filename, sep=\"|\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframe into a loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(df, page_content_column=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulnayak/.pyenv/versions/3.11.4/envs/OpenAI@3114/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Helper funciton to combine tokens into names\n",
    "\n",
    "stop_words = [\"\", \"the\", \"The\", \"THE\", \"Sir\", \"Dr\", \"Mr\", \"of\", \"and\"]\n",
    "# stop_words = []\n",
    "def combine_tokens(ner_results):\n",
    "    name = \"\"\n",
    "    entities_list = []\n",
    "    entity = \"NA\"\n",
    "    current_word_start = 0\n",
    "    prev_word_end = 0\n",
    "    for res in ner_results:\n",
    "        word = res['word']\n",
    "        current_word_start = res['start']\n",
    "        if (word[0] == \"▁\") or (current_word_start > prev_word_end):\n",
    "            ## Save previous name\n",
    "            if not ( name in stop_words or len(name)<=2):\n",
    "                ## If entity is not set yet, then set current entity.\n",
    "                entity = res['entity'] if entity == \"NA\" else entity\n",
    "                ## removing trailing hypens from the names before saving\n",
    "                entities_list = entities_list + [{'name': name.rstrip(\"-\"), 'entity': entity}]\n",
    "            name = re.sub(r'[^a-zA-Z0-9\\-]', '', word)\n",
    "            entity = res['entity']\n",
    "        # elif not word in [',', \"'\", \".\", \"'\", \";\", \"(\", \")\"]:\n",
    "        else:\n",
    "            # Remove all the special characters except '-' from the token\n",
    "            # Add token to the ongoing name. \n",
    "            name = name + re.sub(r'[^a-zA-Z0-9\\-]', '', word)\n",
    "            \n",
    "        prev_word_end = res['end']\n",
    "    \n",
    "    ## append the last name\n",
    "    entities_list = entities_list + [{'name': name, 'entity': entity}]\n",
    "    ## Return\n",
    "    return entities_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Get names entities\n",
    "def recognise_named_entities(text, pipeline_model):\n",
    "    ner_results = pipeline_model(text)\n",
    "    return ner_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Named Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277456901"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Roberta based NER\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"2rtl3/mn-xlm-roberta-base-named-entity\")\n",
    "roberta_model = AutoModelForTokenClassification.from_pretrained(\"2rtl3/mn-xlm-roberta-base-named-entity\")\n",
    "nlp_roberta = pipeline(\"ner\", model=roberta_model, tokenizer=roberta_tokenizer)\n",
    "roberta_model.num_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "results = []\n",
    "for doc in docs[10:30]:\n",
    "    ner_results = recognise_named_entities(doc.page_content, nlp_roberta)\n",
    "    results = results + ner_results \n",
    "    entities = entities + combine_tokens(ner_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# person_entities = filter(lambda x:  True if (x['entity'] == 'PER') else False, entities)\n",
    "# location_entities = filter(lambda x:  True if (x['entity'] == 'LOC') else False, entities)\n",
    "# misc_entities = filter(lambda x:  True if (x['entity'] == 'MISC') else False, entities)\n",
    "\n",
    "\n",
    "df_entities= pd.DataFrame(entities)\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# print(text)\n",
    "# for entity in entities:\n",
    "#     print(entity)\n",
    "\n",
    "# for res in ner_results:\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[29]\n",
    "ner_results = recognise_named_entities(doc.page_content, nlp_roberta)\n",
    "entities = combine_tokens(ner_results)\n",
    "df_entities= pd.DataFrame(entities)\n",
    "df_results = pd.DataFrame(ner_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel, AutoTokenizer\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
    "# model = AutoModel.from_pretrained('ai4bharat/indic-bert')\n",
    "\n",
    "# inputs = tokenizer(\"After Abhimanyu's marriage, there was royal festival and everyone was pleased\", return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# outputs = model(**inputs)\n",
    "\n",
    "# outputs.pooler_output.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(outputs))\n",
    "# out = outputs.last_hidden_state\n",
    "# print(out.shape)\n",
    "# out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_label_classes = out.argmax(-1)\n",
    "# classes = predicted_label_classes.squeeze().tolist()\n",
    "# print(classes)\n",
    "\n",
    "# tokenizer.decode(token_ids=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.tensor([1, 1, 1]).unsqueeze(0)  # Batch size 1\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Sauti said. \\'Then when the night had passed away and the sun had risen\\nin the morning, O thou whose wealth is asceticism, the two sisters Kadru\\nand Vinata, having laid a wager about slavery, went with haste and\\nimpatience to view the steed Uchchaishravas from a near point. On their\\nway they saw the Ocean, that receptacle of waters, vast and deep, rolling\\nand tremendously roaring, full of fishes large enough to swallow the\\nwhale, and abounding with huge makaras and creatures of various forms by\\nthousands, and rendered inaccessible by the presence of other terrible,\\nmonster-shaped, dark, and fierce aquatic animals, abounding with\\ntortoises and crocodiles, the mine of all kinds of gems, the home of\\nVaruna (the water-God), the excellent and beautiful residence of the\\nNagas, the lord of all rivers, the abode of the subterranean fire, the\\nfriend (or asylum) of the Asuras, the terror of all creatures, the grand\\nreservoir of water, and ever immutable. It is holy, beneficial to the\\ngods, and is the great source of nectar; without limits, inconceivable,\\nsacred, and highly wonderful. It is dark, terrible with the sound of\\naquatic creatures, tremendously roaring, and full of deep whirl-pools. It\\nis an object of terror to all creatures. Moved by the winds blowing from\\nits shores and heaving high, agitated and disturbed, it seems to dance\\neverywhere with uplifted hands represented by its surges. Full of\\nswelling billows caused by the waxing and waning of the moon the parent\\nof Vasudeva\\'s great conch called Panchajanya, the great mine of gems, its\\nwaters were formerly disturbed in consequence of the agitation caused\\nwithin them by the Lord Govinda of immeasurable prowess when he had\\nassumed the form of a wild boar for raising the (submerged) Earth. Its\\nbottom, lower than the nether regions, the vow observing regenerate Rishi\\nAtri could not fathom after (toiling for) a hundred years. It becomes the\\nbed of the lotus-naveled Vishnu when at the termination of every Yuga\\nthat deity of immeasurable power enjoys yoga-nidra, the deep sleep under\\nthe spell of spiritual meditation. It is the refuge of Mainaka fearful of\\nfalling thunder, and the retreat of the Asuras overcome in fierce\\nencounters. It offers water as sacrificial butter to the blazing fire\\nissuing from the mouth of Varava (the Ocean-mare). It is fathomless and\\nwithout limits, vast and immeasurable, and the lord of rivers.\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[103].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
