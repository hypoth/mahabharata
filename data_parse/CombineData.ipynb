{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine summaries from Tinytales, Wikipedia, and Tilaks Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(\"../text\")\n",
    "directory_tilak = Path(\"../text/KaggleTilak/books\")\n",
    "directory_tinytales = Path(\"../text/TinyTales\")\n",
    "directory_wikipedia = Path(\"../text/Wikipedia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_number', 'book_name', 'chapter_name', 'title', 'commentary',\n",
       "       'text', 'section_number', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_data = pd.read_csv(directory_tilak/'complete_text_lines.csv', sep=\";\")\n",
    "kaggle_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'section_number', 'title', 'chapter_number', 'chapter_name',\n",
       "       'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinytales_data = pd.read_csv(directory_tinytales/'mahabharata_tiny_tales_stories.csv', sep=\";\")\n",
    "tinytales_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book', 'source', 'title', 'book_number', 'description', 'text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_data = pd.read_csv(directory_wikipedia/'wikipedia_parva_summary.csv', sep=\";\")\n",
    "\n",
    "## Droping unnecessary columns\n",
    "wikipedia_data.drop(['start_chapter', 'end_chapter'], axis=1, inplace=True)\n",
    "wikipedia_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the dataframes into one bid dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle data dims (2376, 8) \n",
      " TinyTales data dims (200, 6) \n",
      " Wikipedia data dims (19, 6) \n",
      " Final data dims (2595, 11)\n",
      "Final data columns \n",
      " Index(['book_number', 'book_name', 'chapter_name', 'title', 'commentary',\n",
      "       'text', 'section_number', 'source', 'chapter_number', 'book',\n",
      "       'description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_combined = pd.concat([kaggle_data, tinytales_data, wikipedia_data])\n",
    "print(\n",
    "    \"Kaggle data dims\",  kaggle_data.shape, \"\\n\",\n",
    "    \"TinyTales data dims\", tinytales_data.shape, \"\\n\",\n",
    "    \"Wikipedia data dims\", wikipedia_data.shape, \"\\n\",\n",
    "    \"Final data dims\", df_combined.shape)\n",
    "\n",
    "print(\"Final data columns \\n\", df_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tokens for each text row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per row 167.22851637764933\n",
      "Totak number of tokens 433958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_name = \"cl100k_base\"\n",
    "encoding = tiktoken.get_encoding(encoder_name)\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "## Calculat the text tokens per row\n",
    "df_combined['num_text_tokens'] = df_combined['text'].apply(num_tokens_from_string)\n",
    "\n",
    "print(\"Average tokens per row\", statistics.mean(df_combined['num_text_tokens']))\n",
    "print(\"Totak number of tokens\", sum(df_combined['num_text_tokens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the final dataframe into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_combined.to_csv(directory/'combined.csv', index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_number        float64\n",
       "book_name           object\n",
       "chapter_name        object\n",
       "title               object\n",
       "commentary          object\n",
       "text                object\n",
       "section_number     float64\n",
       "source              object\n",
       "chapter_number     float64\n",
       "book                object\n",
       "description         object\n",
       "num_text_tokens      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
